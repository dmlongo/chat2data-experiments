{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/x1/zz862rrj7zlbxftbb9c2wf1h0000gn/T/ipykernel_28206/1060680853.py:1: LangChainDeprecationWarning: The class `OpenAIEmbeddings` was deprecated in LangChain 0.0.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import OpenAIEmbeddings``.\n",
      "  embeddings_model = OpenAIEmbeddings()\n"
     ]
    }
   ],
   "source": [
    "embeddings_model = OpenAIEmbeddings()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Dataset Preparation"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400\n",
      "400\n",
      "400\n",
      "200\n",
      "200\n",
      "200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/edacicek/anaconda3/envs/simple_env/lib/python3.10/site-packages/pandas/core/computation/expressions.py:21: UserWarning: Pandas requires version '2.8.4' or newer of 'numexpr' (version '2.8.3' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n",
      "/Users/edacicek/anaconda3/envs/simple_env/lib/python3.10/site-packages/pandas/core/arrays/masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('../../data/disease_ontology.csv')\n",
    "\n",
    "df_positive = df[df['label']==True]\n",
    "df_negative = df[df['label']==False]\n",
    "\n",
    "df_train_pos = df_positive.iloc[:200]\n",
    "df_pos = df_positive.iloc[200:]\n",
    "\n",
    "df_train_neg = df_negative.iloc[:200]\n",
    "df_neg = df_negative.iloc[200:]\n",
    "\n",
    "\n",
    "train_x_1 = df_train_pos['description_of_candidate_entity'].tolist() + df_train_neg['description_of_candidate_entity'].tolist()\n",
    "train_x_2 = df_train_pos['description_of_focal_entity'].tolist() + df_train_neg['description_of_focal_entity'].tolist()\n",
    "print(len(train_x_1))\n",
    "print(len(train_x_2))\n",
    "train_y = [1] * len(df_train_pos) + [0] * len(df_train_neg)\n",
    "print(len(train_y))\n",
    "\n",
    "test_x_1 = df_pos['description_of_candidate_entity'].tolist() + df_neg['description_of_candidate_entity'].tolist()\n",
    "test_x_2 = df_pos['description_of_focal_entity'].tolist() + df_neg['description_of_focal_entity'].tolist()\n",
    "test_y = [1] * len(df_pos) + [0] * len(df_neg)\n",
    "print(len(test_x_1))\n",
    "print(len(test_x_2))\n",
    "print(len(test_y))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "test_names_1 = df_pos['candidate_entity'].tolist() + df_neg['candidate_entity'].tolist()\n",
    "test_names_2 = df_pos['focal_entity'].tolist() + df_neg['focal_entity'].tolist()\n",
    "test_names = list(zip(test_names_1, test_names_2))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Construction of Embeddings derived from disease descriptions"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "train_embeddings = []\n",
    "\n",
    "for definition1, definition2 in list(zip(train_x_1, train_x_2)):\n",
    "    embedding1 = embeddings_model.embed_documents([definition1])[0]\n",
    "    embedding2 = embeddings_model.embed_documents([definition2])[0]\n",
    "    pair_embedding = np.concatenate((embedding1, embedding2))\n",
    "    train_embeddings.append(pair_embedding)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400\n"
     ]
    }
   ],
   "source": [
    "print(len(train_embeddings))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "text_embeddings = []\n",
    "\n",
    "for definition1, definition2 in list(zip(test_x_1, test_x_2)):\n",
    "    embedding1 = embeddings_model.embed_documents([definition1])[0]\n",
    "    embedding2 = embeddings_model.embed_documents([definition2])[0]\n",
    "    pair_embedding = np.concatenate((embedding1, embedding2))\n",
    "    text_embeddings.append(pair_embedding)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    }
   ],
   "source": [
    "print(len(text_embeddings))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "X_train, y_train = shuffle(train_embeddings, train_y, random_state=42)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### EVALUATION WITH DIFFERENT CLASSIFIERS AND THEIR RESULTS"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.65      0.68       100\n",
      "           1       0.68      0.73      0.70       100\n",
      "\n",
      "    accuracy                           0.69       200\n",
      "   macro avg       0.69      0.69      0.69       200\n",
      "weighted avg       0.69      0.69      0.69       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logistic_classifier = LogisticRegression()\n",
    "logistic_classifier.fit(X_train, y_train)\n",
    "logistic_predictions = logistic_classifier.predict(text_embeddings)\n",
    "print(\"Logistic Regression:\")\n",
    "print(classification_report(test_y, logistic_predictions))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "cm = confusion_matrix(test_y, logistic_predictions)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Results\n",
      "Accuracy:   0.69\n",
      "Precision:  0.68\n",
      "Recall:     0.73\n",
      "Specificity:0.65\n",
      "F1 Score:   0.70\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Calculate additional metrics\n",
    "accuracy = accuracy_score(test_y, logistic_predictions)\n",
    "precision = precision_score(test_y, logistic_predictions)\n",
    "recall = recall_score(test_y, logistic_predictions)\n",
    "f1 = f1_score(test_y, logistic_predictions)\n",
    "\n",
    "cm = confusion_matrix(test_y, logistic_predictions)\n",
    "tn, fp, fn, tp = cm.ravel()  # only valid for binary classification\n",
    "\n",
    "# Calculate specificity: TN / (TN + FP)\n",
    "specificity = tn / (tn + fp)\n",
    "\n",
    "# Print in desired order\n",
    "print(\"Logistic Regression Results\")\n",
    "print(f\"Accuracy:   {accuracy:.2f}\")\n",
    "print(f\"Precision:  {precision:.2f}\")\n",
    "print(f\"Recall:     {recall:.2f}\")\n",
    "print(f\"Specificity:{specificity:.2f}\")\n",
    "print(f\"F1 Score:   {f1:.2f}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Naive Bayes:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.66      0.68       100\n",
      "           1       0.68      0.73      0.71       100\n",
      "\n",
      "    accuracy                           0.69       200\n",
      "   macro avg       0.70      0.70      0.69       200\n",
      "weighted avg       0.70      0.69      0.69       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Naive Bayes (Gaussian)\n",
    "naive_bayes_classifier = GaussianNB()\n",
    "naive_bayes_classifier.fit(X_train, y_train)\n",
    "naive_bayes_predictions = naive_bayes_classifier.predict(text_embeddings)\n",
    "print(\"\\nNaive Bayes:\")\n",
    "print(classification_report(test_y, naive_bayes_predictions))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GaussianNB Prediction RESULTS\n",
      "Accuracy:   0.69\n",
      "Precision:  0.68\n",
      "Recall:     0.73\n",
      "Specificity:0.66\n",
      "F1 Score:   0.71\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(test_y, naive_bayes_predictions)\n",
    "precision = precision_score(test_y, naive_bayes_predictions)\n",
    "recall = recall_score(test_y, naive_bayes_predictions)\n",
    "f1 = f1_score(test_y, naive_bayes_predictions)\n",
    "\n",
    "cm = confusion_matrix(test_y, naive_bayes_predictions)\n",
    "tn, fp, fn, tp = cm.ravel()  # only valid for binary classification\n",
    "\n",
    "# Calculate specificity: TN / (TN + FP)\n",
    "specificity = tn / (tn + fp)\n",
    "\n",
    "# Print in desired order\n",
    "print(\"GaussianNB Prediction RESULTS\")\n",
    "print(f\"Accuracy:   {accuracy:.2f}\")\n",
    "print(f\"Precision:  {precision:.2f}\")\n",
    "print(f\"Recall:     {recall:.2f}\")\n",
    "print(f\"Specificity:{specificity:.2f}\")\n",
    "print(f\"F1 Score:   {f1:.2f}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MLP Classifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.68      0.68       100\n",
      "           1       0.68      0.69      0.69       100\n",
      "\n",
      "    accuracy                           0.69       200\n",
      "   macro avg       0.69      0.69      0.68       200\n",
      "weighted avg       0.69      0.69      0.68       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# MLP Classifier\n",
    "mlp_classifier = MLPClassifier(hidden_layer_sizes=(512, 128), max_iter=500, random_state=42)\n",
    "mlp_classifier.fit(X_train, y_train)\n",
    "mlp_predictions = mlp_classifier.predict(text_embeddings)\n",
    "print(\"\\nMLP Classifier:\")\n",
    "print(classification_report(test_y, mlp_predictions))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP Classifier RESULTS\n",
      "Accuracy:    0.69\n",
      "Precision:   0.68\n",
      "Recall:      0.69\n",
      "Specificity: 0.68\n",
      "F1 Score:    0.69\n"
     ]
    }
   ],
   "source": [
    "cm = confusion_matrix(test_y, mlp_predictions)\n",
    "tn, fp, fn, tp = cm.ravel()  # only valid for binary classification\n",
    "\n",
    "accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
    "precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
    "f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "\n",
    "# Print in desired order\n",
    "print(\"MLP Classifier RESULTS\")\n",
    "print(f\"Accuracy:    {accuracy:.2f}\")\n",
    "print(f\"Precision:   {precision:.2f}\")\n",
    "print(f\"Recall:      {recall:.2f}\")\n",
    "print(f\"Specificity: {specificity:.2f}\")\n",
    "print(f\"F1 Score:    {f1:.2f}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Common Mistakes:\n",
      "42\n",
      "[('ovarian primitive germ cell tumor', 'polyembryoma of the ovary'), ('ovary epithelial cancer', 'malignant ovarian surface epithelial-stromal neoplasm'), ('schistosomiasis', 'cercarial dermatitis'), ('articular cartilage disease', 'chondromalacia'), ('dyskeratosis congenita', 'Revesz syndrome'), ('histidine metabolism disease', 'histidinemia'), ('lysosomal acid lipase deficiency', 'Wolman disease'), ('bone resorption disease', 'osteoporosis'), ('autosomal genetic disease', 'familial adenomatous polyposis'), ('ovary adenocarcinoma', 'ovarian cystadenocarcinoma'), ('epidermolysis bullosa dystrophica', 'transient bullous dermolysis of the newborn'), ('legionellosis', 'Pontiac fever'), ('language disorder', 'aphasia'), ('nonphotosensitive trichothiodystrophy', 'Sabinas brittle hair syndrome'), ('pertussis', 'Bordetella parapertussis whooping cough'), ('Kyasanur forest disease', 'Alkhurma hemorrhagic fever'), ('hydrophthalmos', 'buphthalmos'), ('writing disorder', 'agraphia'), ('bradyopsia', 'autosomal recessive disease'), ('myelofibrosis', 'myeloid neoplasm'), (\"Pick's disease\", 'primary progressive aphasia'), ('neuroendocrine tumor', 'Scheie syndrome'), ('cerebral lymphoma', 'parietal lobe neoplasm'), ('stomatitis', 'cheilitis'), ('brain ischemia', 'cerebral cavernous malformation'), ('autonomic nervous system disease', 'frontometaphyseal dysplasia'), ('ovarian disease', 'glycine N-methyltransferase deficiency'), ('vaginal benign neoplasm', 'benign familial infantile epilepsy'), ('neuromyelitis optica', 'multiple sclerosis'), ('breast carcinoma in situ', 'petrositis'), ('venous insufficiency', 'hereditary papulotranslucent acrokeratoderma'), ('blepharitis', 'apocrine carcinoma'), ('prion disease', 'chronic fungal otitis externa'), ('hypermethioninemia', 'familial thyroid dyshormonogenesis'), ('meibomian cyst', 'hordeolum externum'), ('cone dystrophy', 'neovascular inflammatory vitreoretinopathy'), ('blood platelet disease', 'Naxos disease'), ('frontotemporal dementia', 'microvillus inclusion disease'), ('lipid metabolism disorder', 'lobular neoplasia'), ('eye lymphoma', 'eye carcinoma'), ('stomach cancer', 'post-thrombotic syndrome'), ('otitis externa', 'chordoma')]\n",
      "\n",
      "ratio for common mistakes to mlp mistakes\n",
      "0.6666666666666666\n",
      "ratio for common mistakes to naive bayes mistakes\n",
      "0.6885245901639344\n",
      "ratio for common mistakes to logistic prediction mistakes\n",
      "0.6774193548387096\n"
     ]
    }
   ],
   "source": [
    "# Compare predictions\n",
    "print(\"Common Mistakes:\")\n",
    "\n",
    "# Identify common mistakes\n",
    "common_mistakes = []\n",
    "common_mistake_tuples_with_label = []\n",
    "common_mistake_tuples = []\n",
    "for i in range(len(test_y)):\n",
    "    actual = test_y[i]\n",
    "    mlp_pred = mlp_predictions[i]\n",
    "    nb_pred = naive_bayes_predictions[i]\n",
    "    lr_pred = logistic_predictions[i]\n",
    "\n",
    "    if actual != mlp_pred and actual != nb_pred and actual != lr_pred:\n",
    "        common_mistakes.append(i)\n",
    "        common_mistake_tuples_with_label.append((test_names[i], actual))\n",
    "        common_mistake_tuples.append(test_names[i])\n",
    "\n",
    "print(len(common_mistakes))\n",
    "print(common_mistake_tuples)\n",
    "print()\n",
    "\n",
    "print('ratio for common mistakes to mlp mistakes')\n",
    "print(len(common_mistakes)/sum([y_!=pred for y_,pred in list(zip(test_y, mlp_predictions))]))\n",
    "\n",
    "print('ratio for common mistakes to naive bayes mistakes')\n",
    "print(len(common_mistakes)/sum([y_!=pred for y_,pred in list(zip(test_y, naive_bayes_predictions))]))\n",
    "\n",
    "print('ratio for common mistakes to logistic prediction mistakes')\n",
    "print(len(common_mistakes)/sum([y_!=pred for y_,pred in list(zip(test_y, logistic_predictions))]))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}